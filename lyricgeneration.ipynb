{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "nlp.Defaults.stop_words |= {\"ya\",\"ai\",\"â„¢\"}\n",
    "from collections import Counter\n",
    "from sylcofunc import sylco\n",
    "import datasets\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import pipeline\n",
    "df=pd.read_csv('data/lyrics-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLyricsFromArtist(df,artist,string=True):\n",
    "    \"\"\"\n",
    "    Collects songlyrics from artist in dfS\n",
    "\n",
    "    :param dfS: Song dataframe to use\n",
    "    :param artist: Name of artist e.g \"Bruno Mars\"\n",
    "    :return: lyric\n",
    "    \"\"\"\n",
    "    artistlink='/'+artist.lower().replace(' ','-')+'/'\n",
    "    lyric=df.loc[df['ALink']==artistlink]['Lyric']\n",
    "    if(not string):\n",
    "        return lyric\n",
    "    else:\n",
    "        return ' '.join(lyric.to_list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Class for Lyric Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricAnalysis:\n",
    "    def __init__(self,lyric):\n",
    "        self.lyric=lyric\n",
    "        self.doc=nlp(lyric)\n",
    "        #Named entities\n",
    "        self.ents=[(ent.text, ent.label_) for ent in self.doc.ents]\n",
    "        #NP chunks\n",
    "        self.nounchunks=[(chunk.text.strip(), chunk.root.tag_) for chunk in self.doc.noun_chunks if chunk.text not in [ent[0] for ent in self.ents] and chunk.text.lower() not in nlp.Defaults.stop_words]\n",
    "        (self.nostopchunks,self.chunkDict)=self.chunksToDict()\n",
    "    \n",
    "    def getEnts(self,label):\n",
    "        return [ent for (ent,entlabel) in self.ents if entlabel==label]\n",
    "    \n",
    "    def chunksToDict(self):\n",
    "        \"\"\"\n",
    "        Turns a list of nounchunks in to a dictionary that sorts them in to stopwords and a list of noun chunks that do not start with stopwords.\n",
    "        \n",
    "        For example:\n",
    "        nounchunks=[('a town', 'NN'), ('a place', 'NN'), ('movie scenes', 'NNS'), ('Noise', 'NNP'), ('the streets', 'NNS')]\n",
    "        \n",
    "        returns:\n",
    "        [('movie scenes', 'NNS'), ('Noise', 'NNP')]\n",
    "        {'a': [('town', 'NN'), ('place', 'NN')], 'the': [('streets', 'NNS')]}\n",
    "        \"\"\"\n",
    "        nostopchunks=[]\n",
    "        chunkDict={}\n",
    "        for chunk in self.nounchunks:\n",
    "            chunkText=chunk[0]\n",
    "            hasStop=False\n",
    "            doc=nlp(chunkText)\n",
    "            for i in range(len(doc)):\n",
    "                if(doc[i].is_stop):\n",
    "                    hasStop=True\n",
    "                else:\n",
    "                    if(hasStop):\n",
    "                        stopwords=doc[:i].__str__()\n",
    "                        rest=doc[i:].__str__()\n",
    "                        if stopwords in chunkDict:\n",
    "                            chunkDict[stopwords].append((rest,chunk[1]))\n",
    "                        else:\n",
    "                            chunkDict[stopwords]=[(rest,chunk[1])]\n",
    "                    break\n",
    "            if(not hasStop):\n",
    "                nostopchunks.append(chunk)\n",
    "        return nostopchunks,chunkDict\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for swap of entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRhyme(word,possibleswaps):\n",
    "    \"\"\"\n",
    "    Return a word from possibleswaps that has the equal amount of syllables as the parameter word\n",
    "    \"\"\"\n",
    "    for possible in possibleswaps:\n",
    "        if(sylco(possible)==sylco(word)):\n",
    "            return possible\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapEnts(fromSong,toArtist,entLabels):\n",
    "    \"\"\"\n",
    "    Swaps the most common entities in fromSong with the most common entities in toArtist.\n",
    "    Does so with the entities with label in entLabels\n",
    "\n",
    "    :param entLabels: list of entity labels to make the swap with\n",
    "    :return: str of new song\n",
    "    \"\"\"\n",
    "    output=fromSong.lyric\n",
    "    changes=[]\n",
    "    used=[]\n",
    "    for label in entLabels:\n",
    "        froments= [ent[0] for ent in Counter(fromSong.getEnts(label)).most_common()] #This sorts by frequency. Ent[0] is the text, ent[1] is the count\n",
    "        toents= [ent[0] for ent in Counter(toArtist.getEnts(label)).most_common()]\n",
    "        for ent in froments:\n",
    "            newEnt=findRhyme(ent,[ent for ent in toents if ent not in used])\n",
    "            output=output.replace(ent,newEnt)\n",
    "            used.append(newEnt)\n",
    "            changes.append((ent,newEnt))\n",
    "    return (output,changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for swap of noun phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds a word with equal syllable count that also has the same tag\n",
    "def findMatch(word,tag,list):\n",
    "    for (lword, ltag) in list:\n",
    "        if sylco(lword)==sylco(word) and tag==ltag:\n",
    "            return lword, ltag  \n",
    "    return word, ltag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapNpsWithStop(fromSong,toArtist):\n",
    "    #neededNps={key : list(toArtist.chunkDict[key]) for key in fromSong.chunkDict.keys()}\n",
    "    #neededNps is the collection of noun chunks that start with the same stopwords one of the chunks in the song.\n",
    "    neededNps={}\n",
    "    needtopop=[]\n",
    "    for key in fromSong.chunkDict.keys():\n",
    "        try:\n",
    "            neededNps[key]=list(toArtist.chunkDict[key])\n",
    "        except:\n",
    "            #So that the algorithm doesnt try to search for missing noun phrases\n",
    "            needtopop.append(key) \n",
    "    \n",
    "    #Not able to do this in upper loop because of change in dict size in loop error\n",
    "    for key in needtopop:\n",
    "        fromSong.chunkDict.pop(key)\n",
    "    \n",
    "    changes=[]\n",
    "    output=fromSong.lyric\n",
    "    for key in fromSong.chunkDict.keys():\n",
    "        #sort by freq\n",
    "        cf=[obj[0] for obj in Counter(fromSong.chunkDict[key]).most_common()]\n",
    "        ct=[obj[0] for obj in Counter(neededNps[key]).most_common()]\n",
    "        for (word,tag) in cf:\n",
    "            newWord, newTag=findMatch(word,tag,ct)\n",
    "            newWord=newWord.replace('\\n',' ')\n",
    "            output=output.replace(f'{key} {word}',f'{key} {newWord}')\n",
    "            try:\n",
    "                ct.remove((newWord,newTag))\n",
    "            except:\n",
    "                pass\n",
    "            changes.append((f'{key} {word}',f'{key} {newWord}'))\n",
    "    return output,changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapNps(fromSong,toArtist):\n",
    "    changes=[]\n",
    "    output=fromSong.lyric\n",
    "    #sort by freq\n",
    "    cf=[chunk[0] for chunk in Counter(fromSong.nostopchunks).most_common()]\n",
    "    ct=[chunk[0] for chunk in Counter(toArtist.nostopchunks).most_common()]\n",
    "    for (word,tag) in cf:\n",
    "        newWord, newTag=findMatch(word,tag,ct)\n",
    "        newWord=newWord.replace('\\n',' ')\n",
    "        output=output.replace(word,newWord)\n",
    "        try:\n",
    "            ct.remove((newWord,newTag))\n",
    "        except:\n",
    "            pass\n",
    "        changes.append((word,newWord))\n",
    "    return output,changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The swap of verbphrases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1r_n9OWV3l-Q"
   },
   "source": [
    "## Preparing the dataset for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhrasesFromArtist(artist):\n",
    "    \"\"\"\n",
    "    Collects songlyrics from artist in df\n",
    "\n",
    "    :param df: Song dataframe to use\n",
    "    :param artist: Name of artist e.g \"Bruno Mars\"\n",
    "    :return: list of lines in songs of artist\n",
    "    \"\"\"\n",
    "    artistlink='/'+artist.lower().replace(' ','-')+'/'\n",
    "    lyric=df.loc[df['ALink']==artistlink]['Lyric']\n",
    "    output=[]\n",
    "    for song in lyric:\n",
    "        phraselist=song.split('\\n')\n",
    "        for phrase in phraselist:\n",
    "            output.append(phrase)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DVHs5aCA3l-_"
   },
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iaAJy5Hu3l_B"
   },
   "outputs": [],
   "source": [
    "#Code from https://huggingface.co/docs/transformers/tasks/language_modeling#preprocess\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-EIELH43l_T"
   },
   "source": [
    "## Masked language modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d4176c0a564ade90e7bf7a97c050a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "username='davidlekve'\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lS2m25YM3l-z"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNewModel(artist):\n",
    "    lyric={'text': getPhrasesFromArtist(df,artist)}\n",
    "    ds=datasets.Dataset.from_dict(lyric)\n",
    "    ds=ds.train_test_split(test_size=0.1)\n",
    "\n",
    "    tokenized_datasets = ds.map(tokenize_function, batched=True, num_proc=1, remove_columns=[\"text\"])\n",
    "\n",
    "    lm_datasets = tokenized_datasets.map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        num_proc=1,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "    model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        f\"{model_name}-finetuned-{artist.lower().replace(' ','-')}\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        push_to_hub=True,\n",
    "    )\n",
    "    #num_train_epochs\n",
    "\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=lm_datasets[\"train\"],\n",
    "        eval_dataset=lm_datasets[\"test\"],\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    # trainer = Trainer(min_epochs=1)\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.push_to_hub()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that changes a word. Replace is not used to minimize changing the middle of a word.\n",
    "def replaceWord(doc,word,newWord):\n",
    "    result = \"\"\n",
    "    changed=False\n",
    "    for token in doc:\n",
    "        if token.text != word:\n",
    "            result += token.text_with_ws\n",
    "        elif (not changed):\n",
    "            result += newWord\n",
    "            result += token.whitespace_\n",
    "            changed=True\n",
    "        else:\n",
    "            result += token.text_with_ws\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeVerbs(song,generator):\n",
    "    phraselist=song.split('\\n')\n",
    "    verbtags=[\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\"]\n",
    "    newText=''\n",
    "    changes=[]\n",
    "    for phrase in phraselist:\n",
    "        verb=None\n",
    "        doc=nlp(phrase)\n",
    "        for word in doc:\n",
    "            if(word.tag_ in verbtags and word.text.lower() not in nlp.Defaults.stop_words):\n",
    "                verb=word.text\n",
    "                break\n",
    "        \n",
    "        if(verb!=None):\n",
    "            \n",
    "            modified=replaceWord(doc,verb,'<mask>')\n",
    "            results=generator(modified)\n",
    "            wordresults=[result['token_str'].strip() for result in results]\n",
    "            newword=findRhyme(verb,wordresults)\n",
    "            try:\n",
    "                index=wordresults.index(newword)\n",
    "                newphrase=results[index]['sequence'].strip()\n",
    "                changes.append((verb,newword))\n",
    "            except:\n",
    "                newphrase=phrase\n",
    "                \n",
    "            newText+=newphrase+'\\n'\n",
    "        else:\n",
    "            newText+=phrase+'\\n'\n",
    "    return newText,changes     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that runs through all the necessary code to change the song.\n",
    "def generate(artistsong):\n",
    "    changes=[]\n",
    "    entsSwapped=swapEnts(artistsong.songAnalysis,artistsong.artistAnalysis,artistsong.entlabels)\n",
    "    artistsong.entresults=entsSwapped\n",
    "    changes.extend(entsSwapped[1])\n",
    "    \n",
    "    nounSwapped=swapNps(artistsong.songAnalysis,artistsong.artistAnalysis)\n",
    "    changes.extend(nounSwapped[1])\n",
    "\n",
    "    stopnounSwapped=swapNpsWithStop(artistsong.songAnalysis,artistsong.artistAnalysis)\n",
    "    lyric=stopnounSwapped[0]\n",
    "\n",
    "    for i in range(len(changes)):\n",
    "        lyric=lyric.replace(changes[i][0],changes[i][1])\n",
    "\n",
    "    changes.extend(stopnounSwapped[1])\n",
    "    artistsong.nounresutls=(lyric,[change for change in changes if change not in entsSwapped[1]])\n",
    "    \n",
    "    verbSwapped=changeVerbs(lyric,artistsong.generator)\n",
    "    artistsong.verbresult=verbSwapped\n",
    "    changes.extend(verbSwapped[1])\n",
    "    artistsong.changes=changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Object that stores all the information\n",
    "class GeneratedLyricsFromArtist:\n",
    "    def __init__(self,artist,song):\n",
    "        self.artistName=artist\n",
    "        self.artistLyric=getLyricsFromArtist(df,self.artistName)\n",
    "        self.artistAnalysis=LyricAnalysis(self.artistLyric)\n",
    "        self.songTitle=song\n",
    "        self.entlabels=['PERSON','FAC','ORG','GPE','LOC']\n",
    "        self.songAnalysis=self.getSongAnalysis()\n",
    "        self.generator=self.getModel()\n",
    "        self.entresults=None\n",
    "        self.nounresutls=None\n",
    "        self.verbresult=None\n",
    "        self.changes=None\n",
    "\n",
    "    def getSongAnalysis(self):\n",
    "        lyric=df.loc[df['SName']==self.songTitle]['Lyric'].head(1).values[0]\n",
    "        return LyricAnalysis(lyric)\n",
    "\n",
    "    def getModel(self):\n",
    "        try:\n",
    "            model=AutoModelForMaskedLM.from_pretrained(f\"{username}/distilroberta-base-finetuned-{self.artistName.lower().replace(' ','-')}\")\n",
    "            return pipeline('fill-mask', model = model, tokenizer=tokenizer)\n",
    "\n",
    "        except:\n",
    "            trainNewModel(self.artistName)\n",
    "            model=AutoModelForMaskedLM.from_pretrained(f\"{username}/distilroberta-base-finetuned-{self.artistName.lower().replace(' ','-')}\")\n",
    "            return pipeline('fill-mask', model = model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The running of Code:\n",
    "\n",
    "Some possible artists are:\n",
    "\n",
    "Kendrick Lamar,\n",
    "The Beatles,\n",
    "Bruno Mars,\n",
    "Billy Ray Cyrus\n",
    "\n",
    "Some possible songs are:\n",
    "'Empire State Of Mind (part. Ii)','Bohemian Rhapsody','Hotline Bling'\n",
    "\n",
    "To get the results, make an GeneratedLyricsFromArtist object with a selected song and artist.\n",
    "Run generate with the object as parameter\n",
    "Print different results\n",
    "\n",
    "object.verbresult[0] is the final result of the song\n",
    "\n",
    "An example is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendricklamar=GeneratedLyricsFromArtist('Kendrick Lamar','Empire State Of Mind (part. Ii)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(kendricklamar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"money, fuckin (2x)\\n\\ngrew up in a fan,\\nThat is famous as a world of picket signs\\nBitch is always loud\\nThere are people all around\\nAnd the streets are mean\\nIf I could make it here\\nI could make it anywhere\\nThat's what they say\\nget my vibe in hoes\\nOr my name in Things going down Metro\\n\\nEven if it ain't all it seems\\nI'm a traffic jam of bitches\\nBaby, I'm from\\n\\n(Compton)\\nfuckin, everybody where bitches are made of\\nThere's nothing you can't do\\nNow you're in fuckin\\nThese streets will make you feel Blow Hurt people will inspire you\\ndo it for fuckin, fuckin, fuckin\\n\\nOn the city, there ain't never a nigga\\nproblems, so hard\\nSuch a melting pot on the mirror selling life\\nBabies pray to God\\nGod a swimming pool\\ntake me down from Nile to the rough Compton\\nSomeone was tonight with a woman\\nFor more than from an empty fridge\\n\\nI'm not to make it by any means\\nI'm a traffic jam of bitches\\nBaby, I'm from\\n\\n(Compton)\\nfuckin, everybody where bitches are made of\\nThere's nothing you can't do\\nNow you're in fuckin\\nThese streets will make you feel Blow Hurt people will inspire you\\ndo it for fuckin, fuckin, fuckin\\n\\n(Compton)\\nOne curse in the truth for the illuminati, big bitches, all looking pretty No place in the truth that can compared\\nPut your feelings in the truth\\ncommunication say yeah, yeah yeaah\\n\\n(Compton)\\nfuckin, everybody where bitches are made of\\nThere's nothing you can't do\\nNow you're in fuckin\\nThese streets will make you feel Blow Hurt people will inspire you\\ntake it for fuckin\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendricklamar.verbresult[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Grew', 'don'),\n",
       " ('Broadway', 'Metro'),\n",
       " ('the Brooklyn Bridge\\nSomeone', 'Long Beach Boulevard\\nFlagging'),\n",
       " ('Chorus', 'Compton'),\n",
       " ('New York', 'fuckin'),\n",
       " ('Harlem', 'Nile'),\n",
       " ('dreams', 'bitches'),\n",
       " ('concrete jungle', 'everybody'),\n",
       " ('brand', 'Blow'),\n",
       " ('new\\nBig lights', 'Hurt people'),\n",
       " ('Oooh oooh', 'money'),\n",
       " ('movie scenes', 'picket signs'),\n",
       " ('Noise', 'Bitch'),\n",
       " ('sirens', 'people'),\n",
       " ('lights', 'hoes'),\n",
       " ('marquees', 'Things'),\n",
       " ('Ladies', 'problems'),\n",
       " ('rock', 'life'),\n",
       " ('Preachers', 'Babies'),\n",
       " ('Hail', 'God'),\n",
       " ('big dreams', 'dollars'),\n",
       " ('Everybody', 'communication'),\n",
       " ('a pocketful', 'a traffic jam'),\n",
       " ('a town', 'a fan'),\n",
       " ('a place', 'a world'),\n",
       " ('a curfew', 'a nigga'),\n",
       " ('a gypsy cab', 'a swimming pool'),\n",
       " ('a hunger', 'a woman'),\n",
       " ('the air', 'the world'),\n",
       " ('the streets', 'the streets'),\n",
       " ('the avenue', 'the city'),\n",
       " ('the corner', 'the mirror'),\n",
       " ('the Brooklyn Bridge', 'the rough Compton'),\n",
       " ('the big city\\nStreet lights', 'the illuminati'),\n",
       " ('the world', 'the truth'),\n",
       " ('my face', 'my vibe'),\n",
       " ('These streets', 'These streets'),\n",
       " ('any means', 'any means'),\n",
       " ('One hand', 'One curse'),\n",
       " ('all looking pretty\\nNo place', 'all looking pretty No place'),\n",
       " ('your lighters', 'your feelings'),\n",
       " ('don', 'grew'),\n",
       " ('Seeing', 'get'),\n",
       " ('found', 'going'),\n",
       " ('got', \"'m\"),\n",
       " ('feel', 'feel'),\n",
       " ('Hear', 'do'),\n",
       " ('work', ','),\n",
       " ('pray', 'pray'),\n",
       " ('swimming', 'swimming'),\n",
       " ('Takes', 'take'),\n",
       " ('sleeps', 'was'),\n",
       " ('going', 'not'),\n",
       " ('got', \"'m\"),\n",
       " ('feel', 'feel'),\n",
       " ('Hear', 'do'),\n",
       " ('feel', 'feel'),\n",
       " ('Hear', 'take')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendricklamar.changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "billyray=GeneratedLyricsFromArtist('Billy Ray Cyrus','Empire State Of Mind (part. Ii)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(billyray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "billyrayHotline=GeneratedLyricsFromArtist('Billy Ray Cyrus','Hotline Bling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(billyrayHotline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Grew', 'don'),\n",
       " ('Broadway', 'Metro'),\n",
       " ('the Brooklyn Bridge\\nSomeone', 'Long Beach Boulevard\\nFlagging'),\n",
       " ('Chorus', 'Compton'),\n",
       " ('New York', 'fuckin'),\n",
       " ('Harlem', 'Nile')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendricklamar.entresults[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billyrayHotline.entresults[1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cabb46fff330aa12eccd7acb2f56fc1e843e5438d6cca0a7b01c2bce153ecb46"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
